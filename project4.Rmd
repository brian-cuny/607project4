---
output: 
  html_document:
    css: custom.css
---

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
library(modelr)
library(tidytext)
library(zoo)
library(scales)
library(ggraph)
library(igraph)
library(topicmodels)
library(httr)
library(RCurl)
library(XML)
library(magrittr)
library(tm)
library(SnowballC)
library(caret)
library(knitr)
set.seed(1234)
```

<div class='jumbotron'>
  <h2 class='display-3 text-uppercase'>Project 4</h2>
  <h4 class='right text-uppercase'>By Brian Weinfeld</h4>
  <div class='clearfix'></div>
  <h5 class='right text-uppercase'>April 11h, 2018</h5>
</div>

<div id='electricity' class='page-header text-uppercase'>
  <h3>Document Classification</h3>
</div>

<div class='well'>
For this project, I used a data set from UCI's Machine Learning Repository which can be found [here](http://archive.ics.uci.edu/ml/datasets.html?format=&task=&att=&area=&numAtt=&numIns=&type=text&sort=attup&view=list). I selected a data set that contained several websites that have been archived and identified as being either about 'Bands', 'BioMedical', 'Goats', or 'Sheep'.

My goal is to perform an analysis on this data and see if I can use machine learning to correctly identify websites based on their words.
</div>

<div class='well'>
I began by writing a function ```Website.Parse``` that is designed to read each webpage, give it with a unique document id and it's associated classification.
</div>

```{r}
Website.Parse <- function(folder, type){
  path <- paste0('C:\\Users\\Brian\\Desktop\\GradClasses\\Spring18\\607\\607project4\\', folder, '\\', type, '\\')
  list.files(path=path, pattern="\\d+") %>%
  map_dfr(~getURL(paste0('file:///', path, .x)) %>% 
            htmlParse() %>%
            xpathSApply('/html//body', xmlValue) %>%
            strsplit(split='\\n') %>%
            unlist() %>%
            as.tibble() %>%
            add_column(type=type, .before=1) %>%
            add_column(id=paste(type, .x, sep='_'), .before=1)
        )
}
```

<div class='well'>
I read in the all the websites and then cleaned up the data using tidytext. In addition I removed all numbers, non-ascii symbols, and numbers. Finally, I removed all stop words and a number of other reoccuring terms that I did not want in the final analysis. My guess is that a few of the websites had malformed tags as all my custom stop words are html tags.
</div>

```{r, warning=FALSE, message=FALSE}
custom.stopwords <- data_frame(word=c('div', 'p', 'h', 'img', 'function'))

data <- c('Bands', 'BioMedical', 'Goats', 'Sheep') %>%
  map_df(~Website.Parse('Train', .)) %>%
  unnest_tokens(word, value) %>%
  anti_join(stop_words) %>%
  anti_join(custom.stopwords) %>%
  filter(!str_detect(word, '(\\d|\\.|[^A-Za-z])+')) %>%
  filter(stringi::stri_enc_mark(word) == 'ASCII') %>%
  mutate(word = wordStem(word)) 
kable(data[1:10, ])
```

<div class='well'>
A quick examination finds 61 Band websites, 136 BioMedical websites, 70 Goats websites, and 65 Sheep websites.
</div>

```{r}
data %>%
  group_by(type) %>%
  summarise(count = n_distinct(id)) %>%
  kable()
```

<div class='well'>
I created a tf_idf table and found the top 10 words for each group.
</div>

```{r}
data.tfidf <- data %>%
  count(type, word) %>%
  bind_tf_idf(word, type, n) %>%
  arrange(type, tf_idf) %>%
  mutate(order = row_number()) %>%
  group_by(type) %>%
  top_n(10, tf_idf)
kable(data.tfidf[1:10, ])
```

<div class='well'>
The below graph shows the plotted data. The words associated with each category all seem reasonable and mostly distinct. This should aid in the identification of websites. The two most similar are both intuitively and statistically Goats and Sheep. In fact, Sheep is one of the top identifiying words in the Goats category. It seems most probably that misclassification would occurr between these two sets.
</div>

```{r}
ggplot(data.tfidf, aes(order, tf_idf, fill=type)) +
  geom_bar(show.legend=FALSE, stat='identity') +
  facet_wrap(~type, scales='free') +
  coord_flip() +
  theme(axis.text.x=element_text(angle=-30, vjust=1, hjust=0)) +
  scale_x_continuous(
    breaks = data.tfidf$order,
    labels = data.tfidf$word
  ) +
  labs(x=NULL,
       y=NULL,
       title='Top 10 Best Identifying Words by Topic')
```

<div id='electricity' class='page-header text-uppercase'>
  <h3>Analysis</h3>
</div>

<div class='well'>
I prepared the data for training and testing by removing the sparse terms and adding an identifying column named type. I randomly selected 10% of the websites in the data and set them aside. The remaining 90% became the training data.
</div>

```{r}
ml.data <- data %>%
  count(type, id, word) %>%
  cast_dtm(id, word, n) %>%
  removeSparseTerms(sparse=0.99) %>%
  as.matrix() %>%
  as.data.frame() %>%
  mutate(type = str_extract(row.names(.), '[^_]+'))

test.numbers <- sample(1:323, 32, replace=FALSE)

train.data <- ml.data %>%
  filter(!(row_number() %in% test.numbers))

test.data <- ml.data %>%
  filter(row_number() %in% test.numbers)
```

<div class='well'>
The training data was run through a random forest model and then the test.data was passed through for prediction. The confusion matrix for the training set shows highly accurate classification.
</div>

```{r}
train.results <- train(type~., data=train.data,
           method='rf',
           trControl=trainControl(method='cv',
                                  number = 2
                                  ),
           verbose=FALSE)

test.results <- predict(train.results, newdata=test.data)

train.results$finalModel
```

<div class='well'>
The model had a very high success rate. Only two websites in the testing set were misidentified. Both of them were, as predicted, due to the similarity between Goats and Sheep websites.
</div>

```{r}
present.results <- data_frame(original=test.data$type, prediction=test.results)

table(present.results$original, present.results$prediction)
```

<div class='alert alert-success'>
The analysis has been highly successful. The random forest model was $\frac{30}{32}=0.9375$ about 94% successful in identifying websites.
</div>